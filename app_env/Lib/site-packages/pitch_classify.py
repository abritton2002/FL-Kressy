import pandas as pd
import numpy as np
import math
import logging
from sqlalchemy import create_engine, pool, text
import threading
import time
from functools import lru_cache

# Logging Configuration - Reduced logging for performance
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.FileHandler('pitch_design.log'), logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# Database Connection with optimized connection pool
DB_CONFIG = {
    'host': '10.200.200.107',
    'user': 'readonlyuser',
    'password': 'pKufhAALb7r9Z0x',
    'database': 'statcast_db'
}
engine = create_engine(
    f"mysql+pymysql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}/{DB_CONFIG['database']}?charset=utf8mb4",
    poolclass=pool.QueuePool,
    pool_size=20,  # Increased pool size
    max_overflow=10,
    pool_pre_ping=True,  # Check connection validity before using
    pool_recycle=3600    # Recycle connections after 1 hour
)

# Pitch Type Mapping
PITCH_TYPE_MAP = {
    "SV": "Slurve", "ST": "Sweeper", "SL": "Slider", 
    "CH": "Changeup", "CU": "Curveball", "FC": "Cutter", 
    "SI": "Sinker", "FF": "Four-Seam Fastball"
}

def get_fastball_matches_advanced(pitch_hand, velocity, spin_rate, v_break, spin_efficiency):
    """
    Advanced fastball matching with bucketing and refined selection
    """
    # Define spin efficiency buckets
    def get_spin_eff_bucket(eff):
        if eff > 0.96:
            return 'Heavy Pronation'
        elif eff > 0.90:
            return 'Pronation Bias'
        elif eff > 0.85:
            return 'Middle'
        elif eff > 0.79:
            return 'Supination Bias'
        else:
            return 'Heavy Supination'

    # Current pitch's spin efficiency bucket
    current_bucket = get_spin_eff_bucket(spin_efficiency)

    # Define bucketing query
    fastball_query = text("""
    WITH FastballBuckets AS (
        SELECT 
            sc_raw.pitcher,
            sc_raw.release_speed,
            sc_raw.release_spin_rate,
            sc_raw.pfx_z * 12 AS vertical_break,
            dl_pitching.spin_eff_release_est2 / 100.0 AS spin_efficiency,
            CASE 
                WHEN dl_pitching.spin_eff_release_est2 / 100.0 > 0.96 THEN 'Heavy Pronation'
                WHEN dl_pitching.spin_eff_release_est2 / 100.0 > 0.90 THEN 'Pronation Bias'
                WHEN dl_pitching.spin_eff_release_est2 / 100.0 > 0.85 THEN 'Middle'
                WHEN dl_pitching.spin_eff_release_est2 / 100.0 > 0.79 THEN 'Supination Bias'
                ELSE 'Heavy Supination'
            END AS spin_eff_bucket
        FROM sc_raw
        JOIN dl_pitching ON sc_raw.pitch_id_raw = dl_pitching.pitch_id_dl_pitch
        WHERE sc_raw.pitch_type = 'FF'
          AND sc_raw.p_throws = :pitch_hand
          AND sc_raw.release_speed BETWEEN :velocity_min AND :velocity_max
          AND sc_raw.release_spin_rate BETWEEN :spin_rate_min AND :spin_rate_max
          AND (sc_raw.pfx_z * 12) BETWEEN :v_break_min AND :v_break_max
    )
    SELECT 
        pitcher,
        release_speed,
        release_spin_rate,
        vertical_break,
        spin_efficiency,
        spin_eff_bucket
    FROM FastballBuckets
    WHERE spin_eff_bucket = :current_bucket
    ORDER BY spin_efficiency
    LIMIT 200
    """)

    # Calculate ranges
    velocity_min = velocity - 2
    velocity_max = velocity + 2
    spin_rate_min = spin_rate - 200
    spin_rate_max = spin_rate + 200
    v_break_range = abs(v_break) * 0.25
    v_break_min = v_break - v_break_range
    v_break_max = v_break + v_break_range

    # Execute query
    with engine.connect() as conn:
        result = conn.execute(fastball_query, {
            'pitch_hand': pitch_hand,
            'velocity_min': velocity_min,
            'velocity_max': velocity_max,
            'spin_rate_min': spin_rate_min,
            'spin_rate_max': spin_rate_max,
            'v_break_min': v_break_min,
            'v_break_max': v_break_max,
            'current_bucket': current_bucket
        })
        
        # Log detailed matching results
        matched_pitchers = []
        matching_details = []
        
        for row in result:
            matched_pitchers.append(row.pitcher)
            matching_details.append({
                'pitcher': row.pitcher,
                'release_speed': row.release_speed,
                'release_spin_rate': row.release_spin_rate,
                'vertical_break': row.vertical_break,
                'spin_efficiency': row.spin_efficiency
            })
        
        logger.info(f"Matched Pitchers in {current_bucket} bucket: {len(matched_pitchers)}")
        logger.info("Matching Pitcher Details:")
        for detail in matching_details[:10]:  # Log first 10 details
            logger.info(f"Pitcher Match: {detail}")
        
        return matched_pitchers

def recommend_secondary_pitches(
    pitch_hand: str, 
    velocity: float, 
    spin_rate: float,
    trackman_h_break: float, 
    v_break: float, 
    release_x_ft: float, 
    release_z_ft: float,
    spin_efficiency: float
) -> pd.DataFrame:
    """
    Recommend up to 3 secondary pitch profiles (2 breaking, 1 other), excluding FS, with ±25% fastball profile.
    Optimized for performance.
    """
    start_time = time.time()
    
    # Adjust release_x for Statcast (positive right from catcher's view)
    statcast_release_x = -release_x_ft if pitch_hand == 'R' else release_x_ft
    
    # Fastball constraints (±25% except velocity ±2 MPH, spin ±200 RPM, spin efficiency ±3%)
    velocity_min = velocity - 2
    velocity_max = velocity + 2
    spin_rate_min = spin_rate - 200
    spin_rate_max = spin_rate + 200
    spin_eff_min = max(0, spin_efficiency - 3)
    spin_eff_max = min(100, spin_efficiency + 3)
    h_break_range = abs(trackman_h_break) * 0.25
    h_break_min = trackman_h_break - h_break_range
    h_break_max = trackman_h_break + h_break_range
    v_break_range = abs(v_break) * 0.25
    v_break_min = v_break - v_break_range
    v_break_max = v_break + v_break_range
    release_x_range = .1
    release_x_min = statcast_release_x - release_x_range
    release_x_max = statcast_release_x + release_x_range
    release_z_range = .1
    release_z_min = release_z_ft - release_z_range
    release_z_max = release_z_ft + release_z_range

    try:
        # Use the new matching method
        pitchers = get_fastball_matches_advanced(
            pitch_hand, velocity, spin_rate, v_break, spin_efficiency
        )
        
        if not pitchers:
            logger.info("No fastball pitchers matched the profile.")
            return pd.DataFrame()
        
        # Convert the pitcher list to a comma-separated string for the IN clause
        pitcher_ids_str = ','.join(str(pid) for pid in pitchers)
        
        # Performance-optimized secondary pitch query with explicit IN clause
        secondary_query = f"""
        SELECT 
            dm.manual_pitch_type_cons AS pitch_type_cons,
            sc_raw.pitch_type,
            COUNT(*) AS pitch_count,
            AVG(sc_raw.release_speed) AS avg_velocity,
            AVG(sc_raw.release_spin_rate) AS avg_spin_rate,
            AVG(-sc_raw.pfx_x * 12) AS avg_h_break,
            AVG(sc_raw.pfx_z * 12) AS avg_v_break,
            AVG(sc_raw.vx0) AS avg_vx0,
            AVG(sc_raw.vy0) AS avg_vy0,
            AVG(sc_raw.vz0) AS avg_vz0,
            AVG(sc_raw.spin_direction_observed) AS avg_spin_direction_observed,
            AVG(dl_pitching.stuff_plus) AS avg_stuff_plus,
            AVG(dl_pitching.spin_eff_release_est2) AS avg_spin_efficiency,
            AVG(dl_pitching.spin_eff_release_est2 / 100.0) AS avg_active_spin,
            sc_raw.p_throws,
            CASE 
                WHEN dm.manual_pitch_type_cons IN ('SL', 'SV', 'CU', 'ST', 'FC') THEN 'Breaking'
                ELSE 'Other'
            END AS pitch_category
        FROM sc_raw
        JOIN dl_pitching ON sc_raw.pitch_id_raw = dl_pitching.pitch_id_dl_pitch
        JOIN dl_misc dm ON sc_raw.pitch_id_raw = dm.pitch_id_dl
        WHERE sc_raw.pitcher IN ({pitcher_ids_str})
          AND sc_raw.pitch_type NOT IN ('FF', 'SI', 'FS')
          AND sc_raw.release_speed IS NOT NULL
          AND sc_raw.release_spin_rate IS NOT NULL
          AND sc_raw.pfx_x IS NOT NULL
          AND sc_raw.pfx_z IS NOT NULL
          AND sc_raw.spin_direction_observed IS NOT NULL
          AND dl_pitching.stuff_plus > 90
        GROUP BY dm.manual_pitch_type_cons, sc_raw.pitch_type, sc_raw.p_throws
        HAVING pitch_count >= 10
        ORDER BY avg_stuff_plus DESC
        LIMIT 30;
        """
        
        # Execute secondary pitch query
        secondary_query_start = time.time()
        pitch_df = pd.read_sql(
            secondary_query,
            engine
        )
        logger.info(f"Secondary pitch query took {time.time() - secondary_query_start:.2f} seconds")
        
        # Log results
        if not pitch_df.empty:
            logger.info(f"Found {len(pitch_df)} potential secondary pitch types")
        else:
            logger.info("No matching secondary pitches found after query.")
            return pd.DataFrame()
        
        # Rank and select with diversity - optimized for speed
        selection_start = time.time()
        breaking_df = pitch_df[pitch_df['pitch_category'] == 'Breaking'].nlargest(2, 'avg_stuff_plus')
        other_df = pitch_df[pitch_df['pitch_category'] == 'Other'].nlargest(1, 'avg_stuff_plus')
        final_df = pd.concat([breaking_df, other_df]).nlargest(3, 'avg_stuff_plus')
        
        if len(final_df) < 3 and len(pitch_df) > len(final_df):
            remaining = 3 - len(final_df)
            additional_df = pitch_df[~pitch_df['pitch_type_cons'].isin(final_df['pitch_type_cons'])].nlargest(remaining, 'avg_stuff_plus')
            final_df = pd.concat([final_df, additional_df]).nlargest(3, 'avg_stuff_plus')
        
        if final_df.empty:
            final_df = pitch_df.nlargest(3, 'avg_stuff_plus')
        
        logger.info(f"Pitch selection took {time.time() - selection_start:.2f} seconds")
        
        # Compute spin components - this is CPU intensive
        spin_start = time.time()
        spin_df = calculate_spin_components_from_averages(final_df)
        logger.info(f"Spin calculation took {time.time() - spin_start:.2f} seconds")
        
        # Join results
        result_df = final_df[[
            'pitch_type_cons', 'pitch_type', 'pitch_count', 'avg_velocity', 'avg_spin_rate',
            'avg_h_break', 'avg_v_break', 'avg_stuff_plus', 'avg_spin_efficiency', 'avg_active_spin'
        ]].join(spin_df[['omega_x', 'omega_y', 'omega_z', 'spin_axis_theta', 'spin_axis_phi']])
        
        logger.info(f"Total recommendation time: {time.time() - start_time:.2f} seconds")
        return result_df
    
    except Exception as e:
        logger.error(f"Error in recommend_secondary_pitches: {e}")
        return pd.DataFrame()

def calculate_spin_components_from_averages(df):
    """Calculate spin components from averaged inputs with null handling. Optimized version."""
    # Pre-compute column renames with a single operation for efficiency
    df = df.rename(columns={
        'avg_vx0': 'vx0',
        'avg_vy0': 'vy0',
        'avg_vz0': 'vz0',
        'avg_spin_rate': 'release_spin_rate',
        'avg_spin_direction_observed': 'spin_direction_observed',
        'avg_active_spin': 'active_spin'
    })
    
    # Handle nulls with fillna for all columns at once
    fill_values = {
        'vx0': 0,
        'vy0': -90,
        'vz0': 0,
        'release_spin_rate': 0,
        'spin_direction_observed': 0,
        'active_spin': 0
    }
    df = df.fillna(fill_values)
    
    # Convert to numpy arrays for faster computation
    vx0 = df['vx0'].to_numpy() * 0.3048
    vy0 = df['vy0'].to_numpy() * 0.3048
    vz0 = df['vz0'].to_numpy() * 0.3048
    
    # Vectorized calculations
    v = np.sqrt(vx0**2 + vy0**2 + vz0**2)
    phi_release = np.arctan2(vx0, vy0)
    theta_release = np.arcsin(vx0 / v)
    
    v_hat_x = np.cos(theta_release) * np.sin(phi_release)
    # Continued from previous code...
    v_hat_y = np.cos(theta_release) * np.cos(phi_release)
    v_hat_z = np.sin(theta_release)
    
    phi = np.deg2rad(df['spin_direction_observed'].to_numpy())
    cos_theta_S = np.sqrt(1 - df['active_spin'].to_numpy()**2)
    
    A = v_hat_x * np.cos(phi) + v_hat_z * np.sin(phi)
    B = v_hat_y
    C = cos_theta_S
    R = np.sqrt(A**2 + B**2)
    
    X = np.arctan2(B, A)
    Theta = np.arcsin(C / R) - X
    
    release_spin_rate = df['release_spin_rate'].to_numpy()
    
    # Calculate omega components
    omega_x = release_spin_rate * np.sin(Theta) * np.cos(phi)
    
    # Handle left/right handed pitchers differently for omega_y
    omega_y = np.where(
        df['p_throws'].to_numpy() == 'L',
        -release_spin_rate * np.cos(Theta),
        release_spin_rate * np.cos(Theta)
    )
    
    omega_z = release_spin_rate * np.sin(Theta) * np.sin(phi)
    
    # Calculate spin axis angles
    spin_axis_theta = np.degrees(np.arctan2(omega_y, np.sqrt(omega_x**2 + omega_z**2)))
    spin_axis_phi = np.degrees(np.arctan2(omega_z, omega_x))
    
    # Create result dataframe
    result = pd.DataFrame({
        'omega_x': omega_x,
        'omega_y': omega_y,
        'omega_z': omega_z,
        'spin_axis_theta': spin_axis_theta,
        'spin_axis_phi': spin_axis_phi
    })
    
    return result

def load_and_filter_college_data(
    pitch_hand, 
    velocity, 
    spin_rate, 
    trackman_h_break, 
    v_break
):
    """Load only relevant data for the given parameters"""
    print(f"Loading and filtering data for {pitch_hand}-handed pitcher with {velocity} mph fastball...")
    
    # Only load necessary columns for initial filtering
    usecols = [
        'PitcherId', 'PitcherThrows', 'TaggedPitchType', 
        'RelSpeed', 'SpinRate', 'HorzBreak', 'InducedVertBreak',
        'PitchCall'
    ]
    
    df = pd.read_csv("data/TM_2024_reg_szn.csv", usecols=usecols)
    
    # Initial conversion and filtering
    df['pitch_hand'] = df['PitcherThrows'].apply(lambda x: x[0])
    
    # Filter for relevant fastballs
    vel_min = velocity * 0.95
    vel_max = velocity * 1.05
    spin_min = spin_rate * 0.85
    spin_max = spin_rate * 1.15
    h_break_min = trackman_h_break * 0.85
    h_break_max = trackman_h_break * 1.15
    v_break_min = v_break * 0.85
    v_break_max = v_break * 1.15
    
    fastballs = df[
        (df['TaggedPitchType'] == 'Fastball') &
        (df['pitch_hand'] == pitch_hand) &
        (df['RelSpeed'] >= vel_min) &
        (df['RelSpeed'] <= vel_max) &
        (df['SpinRate'] >= spin_min) &
        (df['SpinRate'] <= spin_max) &
        (df['HorzBreak'] >= h_break_min) &
        (df['HorzBreak'] <= h_break_max) &
        (df['InducedVertBreak'] >= v_break_min) &
        (df['InducedVertBreak'] <= v_break_max)
    ]
    
    # Get matching pitchers
    matching_pitchers = fastballs['PitcherId'].unique().tolist()
    
    # If we need more pitchers, try relaxing velocity more but keep movement criteria
    if len(matching_pitchers) < 5:
        print("Not enough matches, relaxing velocity constraints...")
        vel_min = velocity * 0.92
        vel_max = velocity * 1.08
        
        fastballs = df[
            (df['TaggedPitchType'] == 'Fastball') &
            (df['pitch_hand'] == pitch_hand) &
            (df['RelSpeed'] >= vel_min) &
            (df['RelSpeed'] <= vel_max) &
            (df['HorzBreak'] >= h_break_min) &
            (df['HorzBreak'] <= h_break_max) &
            (df['InducedVertBreak'] >= v_break_min) &
            (df['InducedVertBreak'] <= v_break_max)
        ]
        matching_pitchers = fastballs['PitcherId'].unique().tolist()
    
    print(f"Found {len(matching_pitchers)} pitchers with similar fastballs")
    
    if not matching_pitchers:
        return pd.DataFrame()
    
    # Now load all necessary data but only for matching pitchers
    usecols = [
        'PitcherId', 'TaggedPitchType', 'RelSpeed', 'SpinRate', 
        'HorzBreak', 'InducedVertBreak', 'RelSide', 'RelHeight',
        'PitchCall', 'vx0', 'vy0', 'vz0', 'SpinAxis', 'PitcherThrows'
    ]
    
    print("Loading detailed data for matching pitchers...")
    # First load the data with just the columns we need
    pitcher_data = pd.read_csv("data/TM_2024_reg_szn.csv", usecols=usecols)
    
    # Then filter for just the pitchers we want
    pitcher_data = pitcher_data[pitcher_data['PitcherId'].isin(matching_pitchers)]
    
    # Add calculated fields
    pitcher_data['is_swing'] = pitcher_data['PitchCall'].isin(['StrikeSwinging', 'FoulBall', 'InPlay'])
    pitcher_data['is_miss'] = pitcher_data['PitchCall'] == 'StrikeSwinging'
    
    return pitcher_data

def college_calculate_spin_components_from_averages(df):
    """Calculate spin components from averaged inputs with null handling. Optimized version."""
    # Pre-compute column renames with a single operation for efficiency
    df = df.rename(columns={
        'vx0_mean': 'vx0',
        'vy0_mean': 'vy0',
        'vz0_mean': 'vz0',
        'avg_spin_rate': 'release_spin_rate',
        'spin_axis_mean': 'spin_direction_observed',
        'avg_active_spin': 'active_spin'
    })
    
    # Handle nulls with fillna for all columns at once
    fill_values = {
        'vx0': 0,
        'vy0': -90,
        'vz0': 0,
        'release_spin_rate': 0,
        'spin_direction_observed': 0,
        'active_spin': 0
    }
    df = df.fillna(fill_values)
    
    # Convert to numpy arrays for faster computation
    vx0 = df['vx0'].to_numpy() * 0.3048
    vy0 = df['vy0'].to_numpy() * 0.3048
    vz0 = df['vz0'].to_numpy() * 0.3048
    
    # Vectorized calculations
    v = np.sqrt(vx0**2 + vy0**2 + vz0**2)
    v[v == 0] = 0.001  # Avoid division by zero
    
    phi_release = np.arctan2(vx0, vy0)
    theta_release = np.arcsin(np.clip(vx0 / v, -1, 1))
    
    v_hat_x = np.cos(theta_release) * np.sin(phi_release)
    v_hat_y = np.cos(theta_release) * np.cos(phi_release)
    v_hat_z = np.sin(theta_release)
    
    # If no spin direction observed, use SpinAxis
    if 'spin_direction_observed' in df.columns and not df['spin_direction_observed'].isna().all():
        phi = np.deg2rad(df['spin_direction_observed'].to_numpy())
    elif 'SpinAxis' in df.columns:
        phi = np.deg2rad(df['SpinAxis'].to_numpy())
    else:
        phi = np.zeros_like(vx0)
    
    cos_theta_S = np.sqrt(1 - np.clip(df['active_spin'].to_numpy(), 0, 1)**2)
    
    A = v_hat_x * np.cos(phi) + v_hat_z * np.sin(phi)
    B = v_hat_y
    C = cos_theta_S
    R = np.sqrt(A**2 + B**2)
    R[R == 0] = 0.001  # Avoid division by zero
    
    X = np.arctan2(B, A)
    Theta = np.arcsin(np.clip(C / R, -1, 1)) - X
    
    release_spin_rate = df['release_spin_rate'].to_numpy()
    
    # Calculate omega components
    omega_x = release_spin_rate * np.sin(Theta) * np.cos(phi)
    
    # Handle left/right handed pitchers differently for omega_y
    is_left = np.array([p == 'L' for p in df['p_throws'].to_numpy()])
    omega_y = np.where(
        is_left,
        -release_spin_rate * np.cos(Theta),
        release_spin_rate * np.cos(Theta)
    )
    
    omega_z = release_spin_rate * np.sin(Theta) * np.sin(phi)
    
    # Calculate spin axis angles
    spin_axis_theta = np.degrees(np.arctan2(omega_y, np.sqrt(omega_x**2 + omega_z**2)))
    spin_axis_phi = np.degrees(np.arctan2(omega_z, omega_x))
    
    # Create result dataframe
    result = pd.DataFrame({
        'omega_x': omega_x,
        'omega_y': omega_y,
        'omega_z': omega_z,
        'spin_axis_theta': spin_axis_theta,
        'spin_axis_phi': spin_axis_phi
    })
    
    return result

def college_recommend_secondary_pitches(
    pitch_hand: str, 
    velocity: float, 
    spin_rate: float,
    trackman_h_break: float, 
    v_break: float, 
    release_x_ft: float, 
    release_z_ft: float,
    spin_efficiency: float
) -> pd.DataFrame:
    """
    Recommend secondary pitch profiles using college dataset,
    based on whiff rate (swing and miss percentage)
    """
    # Load filtered data for matching pitchers
    filtered_data = load_and_filter_college_data(
        pitch_hand, velocity, spin_rate, trackman_h_break, v_break
    )
    
    if filtered_data.empty:
        print("No matching pitchers found")
        return pd.DataFrame()
    
    # Get only secondary pitches, excluding knuckleballs
    secondary_pitches = filtered_data[
        (~filtered_data['TaggedPitchType'].isin(['Fastball', 'Sinker', 'Knuckleball'])) & 
        (filtered_data['SpinRate'] > 800)  # Additional filter to exclude potential unlabeled knuckleballs
    ]
    
    print(f"Found {len(secondary_pitches)} secondary pitches from similar pitchers")
    
    if secondary_pitches.empty:
        return pd.DataFrame()
    
    # Calculate whiff rates for each pitcher and pitch type combination
    pitcher_pitch_metrics = []
    for (pitcher_id, pitch_type), group in secondary_pitches.groupby(['PitcherId', 'TaggedPitchType']):
        swings = group['is_swing'].sum()
        misses = group['is_miss'].sum()
        total_pitches = len(group)
        
        # Lower the threshold for swings needed to be included
        if swings >= 10 and total_pitches >= 20:
            whiff_rate = misses / swings
            
            pitcher_pitch_metrics.append({
                'PitcherId': pitcher_id,
                'pitch_type': pitch_type,
                'total_pitches': total_pitches,
                'swings': swings,
                'misses': misses,
                'whiff_rate': whiff_rate,
                'avg_velocity': group['RelSpeed'].mean(),
                'avg_spin_rate': group['SpinRate'].mean(),
                'avg_h_break': group['HorzBreak'].mean(),
                'avg_v_break': group['InducedVertBreak'].mean(),
                'vx0': group['vx0'].mean() if 'vx0' in group.columns else 0,
                'vy0': group['vy0'].mean() if 'vy0' in group.columns else 0,
                'vz0': group['vz0'].mean() if 'vz0' in group.columns else 0,
                'spin_axis': group['SpinAxis'].mean() if 'SpinAxis' in group.columns else 0,
                'p_throws': pitch_hand
            })
    
    if not pitcher_pitch_metrics:
        print("Not enough data for reliable whiff rate calculations")
        return pd.DataFrame()
    
    # Convert to DataFrame
    metrics_df = pd.DataFrame(pitcher_pitch_metrics)
    
    # For each pitch type, get the top pitches by whiff rate
    pitch_profiles = []
    for pitch_type, type_group in metrics_df.groupby('pitch_type'):
        # Skip if we don't have at least 2 pitchers with this pitch type
        if len(type_group) < 2:
            continue
            
        # Get top pitches by whiff rate
        top_pitches = type_group.nlargest(min(15, len(type_group)), 'whiff_rate')
        
        total_count = top_pitches['total_pitches'].sum()
        total_swings = top_pitches['swings'].sum()
        total_misses = top_pitches['misses'].sum()
        
        # Create aggregate profile
        pitch_profile = {
            'pitch_type_cons': pitch_type,
            'pitch_type': pitch_type,
            'pitch_count': total_count,
            'avg_velocity': top_pitches['avg_velocity'].mean(),
            'avg_spin_rate': top_pitches['avg_spin_rate'].mean(),
            'avg_h_break': top_pitches['avg_h_break'].mean(),
            'avg_v_break': top_pitches['avg_v_break'].mean(),
            'avg_spin_efficiency': 90.0,  # Placeholder
            'whiff_pct': (total_misses / total_swings) if total_swings > 0 else 0,  # Recalculate based on total swings/misses
            'vx0_mean': top_pitches['vx0'].mean(),
            'vy0_mean': top_pitches['vy0'].mean(),
            'vz0_mean': top_pitches['vz0'].mean(),
            'spin_axis_mean': top_pitches['spin_axis'].mean(),
            'p_throws': pitch_hand,
            'pitcher_count': len(top_pitches),  # How many pitchers contributed to this average
            'swing_count': total_swings
        }
        
        pitch_profiles.append(pitch_profile)
    
    if not pitch_profiles:
        print("No valid pitch profiles found")
        return pd.DataFrame()
    
    # Convert to DataFrame
    profiles_df = pd.DataFrame(pitch_profiles)
    
    # Add calculated fields
    profiles_df['avg_active_spin'] = profiles_df['avg_spin_efficiency'] / 100
    profiles_df['avg_stuff_plus'] = (profiles_df['whiff_pct'] / 0.25) * 100
    
    # Categorize pitches
    breaking_pitches = ['Slider', 'Curveball', 'Slurve', 'Sweeper']
    profiles_df['pitch_category'] = profiles_df['pitch_type_cons'].apply(
        lambda x: 'Breaking' if x in breaking_pitches else 'Other'
    )
    
    # Get top recommendations
    breaking = profiles_df[profiles_df['pitch_category'] == 'Breaking'].nlargest(2, 'whiff_pct')
    other = profiles_df[profiles_df['pitch_category'] == 'Other'].nlargest(1, 'whiff_pct')
    
    final_profiles = pd.concat([breaking, other])
    
    # If we don't have enough pitches, just return top 3 overall
    if len(final_profiles) < 3:
        final_profiles = profiles_df.nlargest(3, 'whiff_pct')
    
    # Calculate spin components
    spin_df = college_calculate_spin_components_from_averages(final_profiles)
    
    # Join spin components to the results
    result_df = final_profiles.reset_index(drop=True)
    spin_df = spin_df.reset_index(drop=True)
    result_df = pd.concat([result_df, spin_df], axis=1)
    
    # Round numeric values for display
    for col in result_df.select_dtypes(include=['float']).columns:
        result_df[col] = result_df[col].round(2)
    
    return result_df